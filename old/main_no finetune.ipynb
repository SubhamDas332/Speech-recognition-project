{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb1af896-e80c-4746-a864-ecbaab313713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import math\n",
    "# Device setup for GPU/CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")  # Optional: For debugging\n",
    "from aux import VocabularyBuilder\n",
    "import warnings\n",
    "# Ignore all UserWarnings specifically from torchaudio and torch.nn.modules.transformer\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*torchaudio.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*nested tensors.*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f1a0915-1686-41ef-bc77-a56fe346b7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Vocabulary Generation Successful ---\n",
      "VOCAB_SIZE: 35\n",
      "Characters found:  abcdefghijklmnoprstuvz«»ĉĝĥĵŝŭﬁ\n",
      "\n",
      "CHAR_MAP (First 5 entries):\n",
      "{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, ' ': 3, 'a': 4}\n",
      "\n",
      "--- Next Steps ---\n",
      "The variables CHAR_MAP, INV_CHAR_MAP, and VOCAB_SIZE (=35) are now set and ready for model training.\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "CSV_PATH = 'geo/train.csv'\n",
    "VAL_CSV_PATH = 'geo/dev.csv'\n",
    "DATA_DIR = 'geo/clips'\n",
    "MAX_LENGTH = 200\n",
    "SAMPLE_RATE = 16000  # Assuming 16kHz; adjust if needed\n",
    "N_MELS = 80\n",
    "HOP_LENGTH = 160  # 10ms hop\n",
    "WIN_LENGTH = 400  # 25ms window\n",
    "\n",
    "vocab_builder = VocabularyBuilder(train_csv_path=CSV_PATH, val_csv_path=VAL_CSV_PATH)\n",
    "CHAR_MAP, INV_CHAR_MAP, VOCAB_SIZE = vocab_builder.build_vocab()\n",
    "\n",
    "# 3. Display the results\n",
    "print(\"--- Vocabulary Generation Successful ---\")\n",
    "print(f\"VOCAB_SIZE: {VOCAB_SIZE}\")\n",
    "\n",
    "# Show the characters found (excluding the special tokens)\n",
    "found_chars = ''.join([INV_CHAR_MAP[i] for i in sorted(INV_CHAR_MAP.keys()) if i >= 3])\n",
    "print(f\"Characters found: {found_chars}\")\n",
    "\n",
    "print(\"\\nCHAR_MAP (First 5 entries):\")\n",
    "print({k: v for i, (k, v) in enumerate(CHAR_MAP.items()) if i < 5})\n",
    "\n",
    "print(\"\\n--- Next Steps ---\")\n",
    "print(f\"The variables CHAR_MAP, INV_CHAR_MAP, and VOCAB_SIZE (={VOCAB_SIZE}) are now set and ready for model training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16200534-c0e3-4eb7-987d-c12cadd08c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        self.df = pd.read_csv(csv_path)  # Assumes columns: 'file', 'transcript'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.df.iloc[idx]['file']\n",
    "        transcript = self.df.iloc[idx]['transcript'].strip().lower()\n",
    "\n",
    "        waveform, sr = torchaudio.load(audio_path)\n",
    "        if sr != SAMPLE_RATE:\n",
    "            waveform = torchaudio.transforms.Resample(sr, SAMPLE_RATE)(waveform)\n",
    "\n",
    "        mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=SAMPLE_RATE, n_mels=N_MELS, hop_length=HOP_LENGTH, win_length=WIN_LENGTH, n_fft=WIN_LENGTH\n",
    "        )\n",
    "        mel_spec = torch.log(mel_transform(waveform) + 1e-9)  # Log-Mel\n",
    "        mel_spec = mel_spec.squeeze(0).transpose(0, 1)  # (seq_len, n_mels)\n",
    "\n",
    "        target = [CHAR_MAP['<SOS>']] + [CHAR_MAP[c] for c in transcript if c in CHAR_MAP] + [CHAR_MAP['<EOS>']]\n",
    "        target = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "        return mel_spec, target\n",
    "\n",
    "def collate_fn(batch):\n",
    "    mels, targets = zip(*batch)\n",
    "    mel_lens = torch.tensor([len(m) for m in mels])\n",
    "    target_lens = torch.tensor([len(t) for t in targets])\n",
    "    mels_padded = pad_sequence(mels, batch_first=True, padding_value=0)\n",
    "    targets_padded = pad_sequence(targets, batch_first=True, padding_value=CHAR_MAP['<PAD>'])\n",
    "    return mels_padded, targets_padded, mel_lens, target_lens\n",
    "\n",
    "# Model components\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim=512):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = torch.log(torch.tensor(10000.0)) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[..., None] * emb[None, :]  \n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "class AudioEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=80, hidden_dim=512, num_layers=12, num_heads=8):\n",
    "        super().__init__()\n",
    "        self.conv_sub = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads, dim_feedforward=2048, dropout=0.3, batch_first=True)\n",
    "        self.transformer_enc = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.pos_emb = SinusoidalPosEmb(hidden_dim)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # x: (batch, seq_len, 80)\n",
    "        x = x.transpose(1, 2)  # For conv1d: (batch, 80, seq_len)\n",
    "        x = self.conv_sub(x)  # (batch, 256, seq_len//4)\n",
    "        x = x.transpose(1, 2)  # (batch, seq_len//4, 256)\n",
    "        seq_len = x.size(1)\n",
    "        pos = torch.arange(0, seq_len, device=x.device).unsqueeze(0).repeat(x.size(0), 1)\n",
    "        x = x + self.pos_emb(pos)\n",
    "        mask = torch.arange(seq_len, device=x.device)[None, :] >= (lengths // 4)[:, None]\n",
    "        x = self.transformer_enc(x, src_key_padding_mask=mask)\n",
    "        return x, mask\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.query_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.key_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.value_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.scale = hidden_dim ** -0.5\n",
    "\n",
    "    def forward(self, query, keys, values, mask=None):\n",
    "        q = self.query_proj(query)\n",
    "        k = self.key_proj(keys)\n",
    "        v = self.value_proj(values)\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask.unsqueeze(1), -1e9)\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        context = torch.matmul(attn, v)\n",
    "        return context\n",
    "\n",
    "class RecurrentDecoder(nn.Module):\n",
    "    def __init__(self, embed_dim=512, hidden_dim=1024, enc_dim=512, vocab_size=VOCAB_SIZE, num_layers=4):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=CHAR_MAP['<PAD>'])\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=0.1)\n",
    "        self.memory_proj = nn.Linear(enc_dim, hidden_dim)  \n",
    "        self.attention = Attention(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, vocab_size)  # Concat rnn_out + context\n",
    "        self.pos_emb = SinusoidalPosEmb(embed_dim)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_lengths, memory_mask):\n",
    "        # tgt: (batch, tgt_len)\n",
    "        tgt_emb = self.embedding(tgt)\n",
    "        tgt_seq_len = tgt.size(1)\n",
    "        pos = torch.arange(0, tgt_seq_len, device=tgt.device).unsqueeze(0).repeat(tgt.size(0), 1)\n",
    "        tgt_emb = tgt_emb + self.pos_emb(pos)\n",
    "        packed_tgt = pack_padded_sequence(tgt_emb, tgt_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, _ = self.rnn(packed_tgt)\n",
    "        rnn_out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        \n",
    "        # Project memory to match decoder dim\n",
    "        memory_proj = self.memory_proj(memory)\n",
    "        \n",
    "        # Attention: query=rnn_out, key=value=memory_proj\n",
    "        context = self.attention(rnn_out, memory_proj, memory_proj, memory_mask)\n",
    "        \n",
    "        combined = torch.cat((rnn_out, context), dim=-1)\n",
    "        logits = self.fc(combined)\n",
    "        return logits\n",
    "\n",
    "    def decode_step(self, tgt_token, memory_proj, memory_mask, hidden, pos):\n",
    "        # tgt_token: (batch=1, 1)\n",
    "        tgt_emb = self.embedding(tgt_token)\n",
    "        pos_tensor = torch.tensor([[pos]], device=tgt_emb.device).repeat(tgt_emb.size(0), 1)\n",
    "        tgt_emb = tgt_emb + self.pos_emb(pos_tensor)\n",
    "        rnn_out, hidden = self.rnn(tgt_emb, hidden)\n",
    "        context = self.attention(rnn_out, memory_proj, memory_proj, memory_mask)\n",
    "        combined = torch.cat((rnn_out, context), dim=-1)\n",
    "        logit = self.fc(combined)\n",
    "        return logit, hidden\n",
    "\n",
    "class ASRModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = AudioEncoder(hidden_dim=512, num_layers=6, num_heads=8)  # Reduced from 12\n",
    "        self.decoder = RecurrentDecoder(embed_dim=512, hidden_dim=1024, enc_dim=512, num_layers=2)  # Reduced from 4\n",
    "\n",
    "    def forward(self, src, tgt, src_lengths, tgt_lengths):\n",
    "        enc_out, enc_mask = self.encoder(src, src_lengths)\n",
    "        logits = self.decoder(tgt, enc_out, tgt_lengths, enc_mask)\n",
    "        return logits\n",
    "\n",
    "    def predict(self, src, src_length, max_length=MAX_LENGTH, beam_width=1):\n",
    "        # Added optional beam search (greedy if beam_width=1)\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            enc_out, enc_mask = self.encoder(src.unsqueeze(0), src_length)\n",
    "            memory_proj = self.decoder.memory_proj(enc_out)\n",
    "            if beam_width == 1:\n",
    "                # Existing greedy code\n",
    "                hidden = (torch.zeros(self.decoder.num_layers, 1, self.decoder.hidden_dim, device=src.device),\n",
    "                          torch.zeros(self.decoder.num_layers, 1, self.decoder.hidden_dim, device=src.device))\n",
    "                tgt_token = torch.tensor([[CHAR_MAP['<SOS>']]], device=src.device)\n",
    "                transcription = []\n",
    "                for i in range(max_length):\n",
    "                    logit, hidden = self.decoder.decode_step(tgt_token, memory_proj, enc_mask, hidden, i)\n",
    "                    pred_token = logit.argmax(-1).squeeze().item()\n",
    "                    if pred_token == CHAR_MAP['<EOS>']:\n",
    "                        break\n",
    "                    if pred_token in INV_CHAR_MAP:\n",
    "                        transcription.append(INV_CHAR_MAP[pred_token])\n",
    "                    tgt_token = torch.tensor([[pred_token]], device=src.device)\n",
    "                return ''.join(transcription)\n",
    "            else:\n",
    "                # Simple beam search implementation\n",
    "                beams = [{'seq': [CHAR_MAP['<SOS>']], 'score': 0.0, 'hidden': (torch.zeros(self.decoder.num_layers, 1, self.decoder.hidden_dim, device=src.device),\n",
    "                                                                             torch.zeros(self.decoder.num_layers, 1, self.decoder.hidden_dim, device=src.device))}]\n",
    "                for step in range(max_length):\n",
    "                    new_beams = []\n",
    "                    for beam in beams:\n",
    "                        tgt_token = torch.tensor([[beam['seq'][-1]]], device=src.device)\n",
    "                        logit, new_hidden = self.decoder.decode_step(tgt_token, memory_proj, enc_mask, beam['hidden'], step)\n",
    "                        probs = torch.log_softmax(logit.squeeze(0).squeeze(0), dim=-1)\n",
    "                        topk_probs, topk_tokens = probs.topk(beam_width)\n",
    "                        for p, t in zip(topk_probs, topk_tokens):\n",
    "                            new_seq = beam['seq'] + [t.item()]\n",
    "                            new_score = beam['score'] + p.item()\n",
    "                            new_beams.append({'seq': new_seq, 'score': new_score, 'hidden': new_hidden})\n",
    "                    beams = sorted(new_beams, key=lambda b: b['score'], reverse=True)[:beam_width]\n",
    "                    if beams[0]['seq'][-1] == CHAR_MAP['<EOS>']:\n",
    "                        break\n",
    "                best_seq = beams[0]['seq'][1:]  # Skip <SOS>\n",
    "                transcription = [INV_CHAR_MAP[t] for t in best_seq if t in INV_CHAR_MAP and t != CHAR_MAP['<EOS>']]\n",
    "                return ''.join(transcription)\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()  \n",
    "    total_loss = 0\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for mels, targets, mel_lens, target_lens in dataloader:\n",
    "            mels = mels.to(device)\n",
    "            targets = targets.to(device)\n",
    "            mel_lens = mel_lens.to(device)\n",
    "            target_lens = target_lens.to(device)\n",
    "\n",
    "            input_tgt = targets[:, :-1]\n",
    "            label = targets[:, 1:]\n",
    "            input_tgt_lens = target_lens - 1\n",
    "            \n",
    "            logits = model(mels, input_tgt, mel_lens, input_tgt_lens)\n",
    "            loss = criterion(logits.reshape(-1, VOCAB_SIZE), label.reshape(-1))\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03350463-a62c-4960-ba67-d49f630719a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AudioDataset(CSV_PATH)\n",
    "val_dataset = AudioDataset(VAL_CSV_PATH)  \n",
    "\n",
    "BATCH_SIZE = 64\n",
    "dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn) \n",
    "\n",
    "model = ASRModel()\n",
    "model = model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.06,momentum=0.8)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=CHAR_MAP['<PAD>'])\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6)\n",
    "early_stopping_patience = 7\n",
    "patience_counter = 3\n",
    "best_val_loss = math.inf\n",
    "best_model_path = 'asr_best_model.pth'\n",
    "\n",
    "num_epochs = 120\n",
    "CLIP_VALUE = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdca84ad-90e7-4545-85b9-1aedbe468cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/120 (Train): 100%|████████████████| 94/94 [00:43<00:00,  2.14it/s, batch_loss=2.8116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed, Train Loss: 2.9431, Val Loss: 2.8538, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/120 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=2.5413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed, Train Loss: 2.7136, Val Loss: 2.5740, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/120 (Train): 100%|████████████████| 94/94 [00:41<00:00,  2.24it/s, batch_loss=2.3694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed, Train Loss: 2.4513, Val Loss: 2.3936, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/120 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=2.3179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed, Train Loss: 2.3213, Val Loss: 2.3020, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/120 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.20it/s, batch_loss=2.1771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed, Train Loss: 2.2342, Val Loss: 2.2154, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/120 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.19it/s, batch_loss=2.0855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 completed, Train Loss: 2.1621, Val Loss: 2.1586, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/120 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.20it/s, batch_loss=2.0692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed, Train Loss: 2.1056, Val Loss: 2.1019, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/120 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=2.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 completed, Train Loss: 2.0529, Val Loss: 2.0795, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/120 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.19it/s, batch_loss=1.9898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 completed, Train Loss: 2.0092, Val Loss: 2.0267, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/120 (Train): 100%|███████████████| 94/94 [00:43<00:00,  2.16it/s, batch_loss=1.9493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 completed, Train Loss: 1.9679, Val Loss: 2.0081, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/120 (Train): 100%|███████████████| 94/94 [00:43<00:00,  2.16it/s, batch_loss=1.9088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 completed, Train Loss: 1.9307, Val Loss: 1.9726, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/120 (Train): 100%|███████████████| 94/94 [00:43<00:00,  2.18it/s, batch_loss=1.8498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 completed, Train Loss: 1.8923, Val Loss: 1.9198, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/120 (Train): 100%|███████████████| 94/94 [00:43<00:00,  2.17it/s, batch_loss=1.8963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 completed, Train Loss: 1.8561, Val Loss: 1.8922, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.22it/s, batch_loss=1.8216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 completed, Train Loss: 1.8255, Val Loss: 1.8866, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=1.7569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 completed, Train Loss: 1.7922, Val Loss: 1.8601, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/120 (Train): 100%|███████████████| 94/94 [00:41<00:00,  2.25it/s, batch_loss=1.7946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 completed, Train Loss: 1.7646, Val Loss: 1.8265, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=1.7219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 completed, Train Loss: 1.7349, Val Loss: 1.8145, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.23it/s, batch_loss=1.6846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 completed, Train Loss: 1.7073, Val Loss: 1.7759, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.24it/s, batch_loss=1.6567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 completed, Train Loss: 1.6783, Val Loss: 1.7607, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/120 (Train): 100%|███████████████| 94/94 [00:41<00:00,  2.26it/s, batch_loss=1.6427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 completed, Train Loss: 1.6544, Val Loss: 1.7550, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.23it/s, batch_loss=1.6725]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 completed, Train Loss: 1.6279, Val Loss: 1.7571, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.23it/s, batch_loss=1.6318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 completed, Train Loss: 1.6067, Val Loss: 1.7348, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/120 (Train): 100%|███████████████| 94/94 [00:43<00:00,  2.17it/s, batch_loss=1.6055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 completed, Train Loss: 1.5831, Val Loss: 1.6947, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/120 (Train): 100%|███████████████| 94/94 [00:43<00:00,  2.18it/s, batch_loss=1.5732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 completed, Train Loss: 1.5625, Val Loss: 1.6822, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/120 (Train): 100%|███████████████| 94/94 [00:41<00:00,  2.24it/s, batch_loss=1.5254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 completed, Train Loss: 1.5352, Val Loss: 1.6651, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/120 (Train): 100%|███████████████| 94/94 [00:43<00:00,  2.16it/s, batch_loss=1.5309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 completed, Train Loss: 1.5157, Val Loss: 1.6666, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/120 (Train): 100%|███████████████| 94/94 [00:43<00:00,  2.16it/s, batch_loss=1.5038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 completed, Train Loss: 1.4927, Val Loss: 1.6527, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.20it/s, batch_loss=1.4708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 completed, Train Loss: 1.4743, Val Loss: 1.6515, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.23it/s, batch_loss=1.4364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 completed, Train Loss: 1.4506, Val Loss: 1.6212, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.24it/s, batch_loss=1.4108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 completed, Train Loss: 1.4322, Val Loss: 1.6449, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.23it/s, batch_loss=1.3911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 completed, Train Loss: 1.4137, Val Loss: 1.6143, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/120 (Train): 100%|███████████████| 94/94 [00:43<00:00,  2.18it/s, batch_loss=1.4014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 completed, Train Loss: 1.3940, Val Loss: 1.6124, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=1.3242]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 completed, Train Loss: 1.3745, Val Loss: 1.6213, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/120 (Train): 100%|███████████████| 94/94 [00:43<00:00,  2.18it/s, batch_loss=1.3356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 completed, Train Loss: 1.3543, Val Loss: 1.6066, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=1.4006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 completed, Train Loss: 1.3350, Val Loss: 1.6157, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.22it/s, batch_loss=1.3045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 completed, Train Loss: 1.3194, Val Loss: 1.5960, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.24it/s, batch_loss=1.2843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 completed, Train Loss: 1.3021, Val Loss: 1.5933, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.23it/s, batch_loss=1.2780]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 completed, Train Loss: 1.2807, Val Loss: 1.5681, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=1.2463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 completed, Train Loss: 1.2572, Val Loss: 1.5772, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.22it/s, batch_loss=1.2347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 completed, Train Loss: 1.2431, Val Loss: 1.6207, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/120 (Train): 100%|███████████████| 94/94 [00:43<00:00,  2.18it/s, batch_loss=1.2379]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 completed, Train Loss: 1.2174, Val Loss: 1.6046, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.20it/s, batch_loss=1.2019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 completed, Train Loss: 1.1958, Val Loss: 1.5897, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.23it/s, batch_loss=1.1746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 completed, Train Loss: 1.1714, Val Loss: 1.6347, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.20it/s, batch_loss=1.1253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 completed, Train Loss: 1.1529, Val Loss: 1.5524, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/120 (Train): 100%|███████████████| 94/94 [00:43<00:00,  2.18it/s, batch_loss=1.1040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 completed, Train Loss: 1.1183, Val Loss: 1.5811, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=1.1481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 completed, Train Loss: 1.0942, Val Loss: 1.5700, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.22it/s, batch_loss=1.0706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 completed, Train Loss: 1.0762, Val Loss: 1.5261, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=1.0445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 completed, Train Loss: 1.0365, Val Loss: 1.5362, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.19it/s, batch_loss=0.9667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 completed, Train Loss: 1.0014, Val Loss: 1.5181, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.22it/s, batch_loss=0.9828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 completed, Train Loss: 0.9687, Val Loss: 1.5121, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.23it/s, batch_loss=0.9229]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 completed, Train Loss: 0.9318, Val Loss: 1.4874, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=0.8916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 completed, Train Loss: 0.8934, Val Loss: 1.4920, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=0.9525]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 completed, Train Loss: 0.8631, Val Loss: 1.5131, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.22it/s, batch_loss=0.7929]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 completed, Train Loss: 0.8264, Val Loss: 1.5212, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=0.7590]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 completed, Train Loss: 0.7810, Val Loss: 1.4691, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=0.7668]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 completed, Train Loss: 0.7436, Val Loss: 1.4853, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=0.6871]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 completed, Train Loss: 0.7094, Val Loss: 1.4643, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=0.6459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 completed, Train Loss: 0.6666, Val Loss: 1.4466, LR: 0.060000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.22it/s, batch_loss=0.7228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 completed, Train Loss: 0.6476, Val Loss: 1.4825, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.23it/s, batch_loss=0.6052]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 completed, Train Loss: 0.5941, Val Loss: 1.4766, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/120 (Train): 100%|███████████████| 94/94 [00:41<00:00,  2.25it/s, batch_loss=0.5738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 completed, Train Loss: 0.5673, Val Loss: 1.5147, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.23it/s, batch_loss=0.5770]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 completed, Train Loss: 0.5230, Val Loss: 1.5309, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/120 (Train): 100%|███████████████| 94/94 [00:43<00:00,  2.18it/s, batch_loss=0.5036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 completed, Train Loss: 0.5123, Val Loss: 1.4629, LR: 0.060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/120 (Train): 100%|███████████████| 94/94 [00:43<00:00,  2.17it/s, batch_loss=0.5054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 completed, Train Loss: 0.4719, Val Loss: 1.4868, LR: 0.030000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/120 (Train): 100%|███████████████| 94/94 [00:42<00:00,  2.23it/s, batch_loss=0.3493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 completed, Train Loss: 0.3798, Val Loss: 1.4898, LR: 0.030000\n",
      "\n",
      "Early stopping triggered after 7 epochs without improvement on Val Loss.\n",
      "\n",
      "Loading best model weights from asr_best_model.pth (Val Loss: 1.4466).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch+1}/{num_epochs} (Train)\")\n",
    "    \n",
    "    for batch_idx, (mels, targets, mel_lens, target_lens) in progress_bar:\n",
    "        if total_train_loss != total_train_loss and batch_idx > 0:\n",
    "            print(\"\\nGradient Explosion detected mid-epoch. Breaking...\")\n",
    "            break\n",
    "        mels = mels.to(device)\n",
    "        targets = targets.to(device)\n",
    "        mel_lens = mel_lens.to(device)\n",
    "        target_lens = target_lens.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_tgt = targets[:, :-1]\n",
    "        label = targets[:, 1:]\n",
    "        input_tgt_lens = target_lens - 1\n",
    "\n",
    "        logits = model(mels, input_tgt, mel_lens, input_tgt_lens)\n",
    "        loss = criterion(logits.reshape(-1, VOCAB_SIZE), label.reshape(-1))\n",
    "\n",
    "        if loss.isnan():\n",
    "            print(f\"\\nWarning: NaN loss detected in batch {batch_idx+1}. Skipping batch.\")\n",
    "            continue\n",
    "        if loss.isinf():\n",
    "            print(f\"\\nWarning: Inf loss detected in batch {batch_idx+1}. Skipping batch.\")\n",
    "            continue\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_VALUE)\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        progress_bar.set_postfix(batch_loss=f\"{loss.item():.4f}\")  \n",
    "\n",
    "    if total_train_loss == total_train_loss: \n",
    "        avg_train_loss = total_train_loss / len(dataloader)\n",
    "    else:\n",
    "        avg_train_loss = float('nan')\n",
    "\n",
    "    avg_val_loss = evaluate(model, val_dataloader, criterion, device)\n",
    "    \n",
    "    # Step the Learning Rate Scheduler\n",
    "    if avg_val_loss == avg_val_loss:\n",
    "        scheduler.step(avg_val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    # Early Stopping Check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path) \n",
    "        status = \" (Saving Best Model)\"\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        status = \"\"\n",
    "        \n",
    "    print(f'Epoch {epoch+1} completed, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, LR: {current_lr:.6f}{status}')\n",
    "    \n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(f\"\\nEarly stopping triggered after {patience_counter} epochs without improvement on Val Loss.\")\n",
    "        break\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    print(f\"\\nLoading best model weights from {best_model_path} (Val Loss: {best_val_loss:.4f}).\")\n",
    "    model.load_state_dict(torch.load(best_model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "789c2454-dd90-42c5-9947-4ae9cfa22f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting transcripts: 100%|████████████████████████████| 1000/1000 [01:14<00:00, 13.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of predicted_df:\n",
      "                  file                                         transcript\n",
      "0  geo/clips/dev_0.wav  ili betez grizgaditam betomum giu lumgaz lin l...\n",
      "1  geo/clips/dev_1.wav  por naljoma gaj baldaŭ truviĝas imtirmacea luĝ...\n",
      "2  geo/clips/dev_2.wav                             li vareĝiz teez tirazi\n",
      "3  geo/clips/dev_3.wav                    zid em la lamdoj eztez elegteta\n",
      "4  geo/clips/dev_4.wav  gaj la ĝemerala magcimto em la jomaj gumzirfeztoj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "MODEL_PATH = 'asr_best_model.pth'\n",
    "TEST_CSV_PATH = \"geo/dev.csv\"\n",
    "model = ASRModel().to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "# Load test CSV\n",
    "test_df = pd.read_csv(TEST_CSV_PATH)\n",
    "predicted_df = test_df.copy()\n",
    "predicted_df['transcript'] = predicted_df['transcript'].astype('object') # Fix dtype upfront\n",
    "# Predict for each row with progress and error handling\n",
    "for idx, row in tqdm(predicted_df.iterrows(), total=len(predicted_df), desc=\"Predicting transcripts\"):\n",
    "    try:\n",
    "        audio_path = row['file']\n",
    "        waveform, sr = torchaudio.load(audio_path)\n",
    "        if sr != SAMPLE_RATE:\n",
    "            waveform = torchaudio.transforms.Resample(sr, SAMPLE_RATE)(waveform)\n",
    "        mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=SAMPLE_RATE, n_mels=N_MELS, hop_length=HOP_LENGTH, win_length=WIN_LENGTH, n_fft=WIN_LENGTH\n",
    "        )\n",
    "        mel_spec = torch.log(mel_transform(waveform) + 1e-9).squeeze(0).transpose(0, 1)\n",
    "        src_length = torch.tensor([mel_spec.size(0)])\n",
    "        prediction = model.predict(mel_spec.to(device), src_length.to(device), beam_width=3)\n",
    "        predicted_df.at[idx, 'transcript'] = prediction\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing index {idx} (file: {audio_path}): {e}\")\n",
    "        predicted_df.at[idx, 'transcript'] = '' # Set empty on error\n",
    "# Verify DataFrame before saving\n",
    "print(\"\\nSample of predicted_df:\")\n",
    "print(predicted_df.head())\n",
    "# Ensure transcript column contains only strings\n",
    "predicted_df['transcript'] = predicted_df['transcript'].fillna('').astype(str)\n",
    "# Save updated CSV\n",
    "output_csv = 'predicted_dev.csv'\n",
    "predicted_df.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2c91508-2bab-430f-a36c-b60e4aa03e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 1.039442545358927\n",
      "CER: 0.7458841847365649\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from jiwer import wer, cer\n",
    "\n",
    "df_gt = pd.read_csv(\"geo/dev.csv\")               # ground truth\n",
    "df_pred = pd.read_csv(\"predicted_dev.csv\")   # predictions\n",
    "\n",
    "# Ensure both are sorted the same way (optional but recommended)\n",
    "df_gt = df_gt.sort_values(\"file\").reset_index(drop=True)\n",
    "df_pred = df_pred.sort_values(\"file\").reset_index(drop=True)\n",
    "\n",
    "df_gt['transcript'] = df_gt['transcript'].fillna('').astype(str)\n",
    "df_pred['transcript'] = df_pred['transcript'].fillna('').astype(str)\n",
    "\n",
    "gt_texts = df_gt[\"transcript\"].tolist()\n",
    "pred_texts = df_pred[\"transcript\"].tolist()\n",
    "\n",
    "\n",
    "overall_wer = wer(gt_texts, pred_texts)\n",
    "overall_cer = cer(gt_texts, pred_texts)\n",
    "\n",
    "print(\"WER:\", overall_wer)\n",
    "print(\"CER:\", overall_cer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796f4c3c-e464-4c5e-8272-c7c4b76b7c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
