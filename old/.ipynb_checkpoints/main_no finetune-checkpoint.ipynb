{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb1af896-e80c-4746-a864-ecbaab313713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import math\n",
    "# Device setup for GPU/CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")  # Optional: For debugging\n",
    "from aux import VocabularyBuilder\n",
    "import warnings\n",
    "# Ignore all UserWarnings specifically from torchaudio and torch.nn.modules.transformer\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*torchaudio.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*nested tensors.*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f1a0915-1686-41ef-bc77-a56fe346b7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Vocabulary Generation Successful ---\n",
      "VOCAB_SIZE: 35\n",
      "Characters found:  abcdefghijklmnoprstuvz«»ĉĝĥĵŝŭﬁ\n",
      "\n",
      "CHAR_MAP (First 5 entries):\n",
      "{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, ' ': 3, 'a': 4}\n",
      "\n",
      "--- Next Steps ---\n",
      "The variables CHAR_MAP, INV_CHAR_MAP, and VOCAB_SIZE (=35) are now set and ready for model training.\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "CSV_PATH = 'geo/train.csv'\n",
    "VAL_CSV_PATH = 'geo/dev.csv'\n",
    "DATA_DIR = 'geo/clips'\n",
    "MAX_LENGTH = 200\n",
    "SAMPLE_RATE = 16000  # Assuming 16kHz; adjust if needed\n",
    "N_MELS = 80\n",
    "HOP_LENGTH = 160  # 10ms hop\n",
    "WIN_LENGTH = 400  # 25ms window\n",
    "\n",
    "vocab_builder = VocabularyBuilder(train_csv_path=CSV_PATH, val_csv_path=VAL_CSV_PATH)\n",
    "CHAR_MAP, INV_CHAR_MAP, VOCAB_SIZE = vocab_builder.build_vocab()\n",
    "\n",
    "# 3. Display the results\n",
    "print(\"--- Vocabulary Generation Successful ---\")\n",
    "print(f\"VOCAB_SIZE: {VOCAB_SIZE}\")\n",
    "\n",
    "# Show the characters found (excluding the special tokens)\n",
    "found_chars = ''.join([INV_CHAR_MAP[i] for i in sorted(INV_CHAR_MAP.keys()) if i >= 3])\n",
    "print(f\"Characters found: {found_chars}\")\n",
    "\n",
    "print(\"\\nCHAR_MAP (First 5 entries):\")\n",
    "print({k: v for i, (k, v) in enumerate(CHAR_MAP.items()) if i < 5})\n",
    "\n",
    "print(\"\\n--- Next Steps ---\")\n",
    "print(f\"The variables CHAR_MAP, INV_CHAR_MAP, and VOCAB_SIZE (={VOCAB_SIZE}) are now set and ready for model training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16200534-c0e3-4eb7-987d-c12cadd08c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        self.df = pd.read_csv(csv_path)  # Assumes columns: 'file', 'transcript'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.df.iloc[idx]['file']\n",
    "        transcript = self.df.iloc[idx]['transcript'].strip().lower()\n",
    "\n",
    "        waveform, sr = torchaudio.load(audio_path)\n",
    "        if sr != SAMPLE_RATE:\n",
    "            waveform = torchaudio.transforms.Resample(sr, SAMPLE_RATE)(waveform)\n",
    "\n",
    "        mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=SAMPLE_RATE, n_mels=N_MELS, hop_length=HOP_LENGTH, win_length=WIN_LENGTH, n_fft=WIN_LENGTH\n",
    "        )\n",
    "        mel_spec = torch.log(mel_transform(waveform) + 1e-9)  # Log-Mel\n",
    "        mel_spec = mel_spec.squeeze(0).transpose(0, 1)  # (seq_len, n_mels)\n",
    "\n",
    "        target = [CHAR_MAP['<SOS>']] + [CHAR_MAP[c] for c in transcript if c in CHAR_MAP] + [CHAR_MAP['<EOS>']]\n",
    "        target = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "        return mel_spec, target\n",
    "\n",
    "def collate_fn(batch):\n",
    "    mels, targets = zip(*batch)\n",
    "    mel_lens = torch.tensor([len(m) for m in mels])\n",
    "    target_lens = torch.tensor([len(t) for t in targets])\n",
    "    mels_padded = pad_sequence(mels, batch_first=True, padding_value=0)\n",
    "    targets_padded = pad_sequence(targets, batch_first=True, padding_value=CHAR_MAP['<PAD>'])\n",
    "    return mels_padded, targets_padded, mel_lens, target_lens\n",
    "\n",
    "# Model components\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim=512):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = torch.log(torch.tensor(10000.0)) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[..., None] * emb[None, :]  \n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "class AudioEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=80, hidden_dim=512, num_layers=12, num_heads=8):\n",
    "        super().__init__()\n",
    "        self.conv_sub = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads, dim_feedforward=2048, dropout=0.3, batch_first=True)\n",
    "        self.transformer_enc = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.pos_emb = SinusoidalPosEmb(hidden_dim)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # x: (batch, seq_len, 80)\n",
    "        x = x.transpose(1, 2)  # For conv1d: (batch, 80, seq_len)\n",
    "        x = self.conv_sub(x)  # (batch, 256, seq_len//4)\n",
    "        x = x.transpose(1, 2)  # (batch, seq_len//4, 256)\n",
    "        seq_len = x.size(1)\n",
    "        pos = torch.arange(0, seq_len, device=x.device).unsqueeze(0).repeat(x.size(0), 1)\n",
    "        x = x + self.pos_emb(pos)\n",
    "        mask = torch.arange(seq_len, device=x.device)[None, :] >= (lengths // 4)[:, None]\n",
    "        x = self.transformer_enc(x, src_key_padding_mask=mask)\n",
    "        return x, mask\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.query_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.key_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.value_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.scale = hidden_dim ** -0.5\n",
    "\n",
    "    def forward(self, query, keys, values, mask=None):\n",
    "        q = self.query_proj(query)\n",
    "        k = self.key_proj(keys)\n",
    "        v = self.value_proj(values)\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask.unsqueeze(1), -1e9)\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        context = torch.matmul(attn, v)\n",
    "        return context\n",
    "\n",
    "class RecurrentDecoder(nn.Module):\n",
    "    def __init__(self, embed_dim=512, hidden_dim=1024, enc_dim=512, vocab_size=VOCAB_SIZE, num_layers=4):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=CHAR_MAP['<PAD>'])\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=0.1)\n",
    "        self.memory_proj = nn.Linear(enc_dim, hidden_dim)  \n",
    "        self.attention = Attention(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, vocab_size)  # Concat rnn_out + context\n",
    "        self.pos_emb = SinusoidalPosEmb(embed_dim)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_lengths, memory_mask):\n",
    "        # tgt: (batch, tgt_len)\n",
    "        tgt_emb = self.embedding(tgt)\n",
    "        tgt_seq_len = tgt.size(1)\n",
    "        pos = torch.arange(0, tgt_seq_len, device=tgt.device).unsqueeze(0).repeat(tgt.size(0), 1)\n",
    "        tgt_emb = tgt_emb + self.pos_emb(pos)\n",
    "        packed_tgt = pack_padded_sequence(tgt_emb, tgt_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, _ = self.rnn(packed_tgt)\n",
    "        rnn_out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        \n",
    "        # Project memory to match decoder dim\n",
    "        memory_proj = self.memory_proj(memory)\n",
    "        \n",
    "        # Attention: query=rnn_out, key=value=memory_proj\n",
    "        context = self.attention(rnn_out, memory_proj, memory_proj, memory_mask)\n",
    "        \n",
    "        combined = torch.cat((rnn_out, context), dim=-1)\n",
    "        logits = self.fc(combined)\n",
    "        return logits\n",
    "\n",
    "    def decode_step(self, tgt_token, memory_proj, memory_mask, hidden, pos):\n",
    "        # tgt_token: (batch=1, 1)\n",
    "        tgt_emb = self.embedding(tgt_token)\n",
    "        pos_tensor = torch.tensor([[pos]], device=tgt_emb.device).repeat(tgt_emb.size(0), 1)\n",
    "        tgt_emb = tgt_emb + self.pos_emb(pos_tensor)\n",
    "        rnn_out, hidden = self.rnn(tgt_emb, hidden)\n",
    "        context = self.attention(rnn_out, memory_proj, memory_proj, memory_mask)\n",
    "        combined = torch.cat((rnn_out, context), dim=-1)\n",
    "        logit = self.fc(combined)\n",
    "        return logit, hidden\n",
    "\n",
    "class ASRModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = AudioEncoder(hidden_dim=512, num_layers=6, num_heads=8)  # Reduced from 12\n",
    "        self.decoder = RecurrentDecoder(embed_dim=512, hidden_dim=1024, enc_dim=512, num_layers=2)  # Reduced from 4\n",
    "\n",
    "    def forward(self, src, tgt, src_lengths, tgt_lengths):\n",
    "        enc_out, enc_mask = self.encoder(src, src_lengths)\n",
    "        logits = self.decoder(tgt, enc_out, tgt_lengths, enc_mask)\n",
    "        return logits\n",
    "\n",
    "    def predict(self, src, src_length, max_length=MAX_LENGTH, beam_width=1):\n",
    "        # Added optional beam search (greedy if beam_width=1)\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            enc_out, enc_mask = self.encoder(src.unsqueeze(0), src_length)\n",
    "            memory_proj = self.decoder.memory_proj(enc_out)\n",
    "            if beam_width == 1:\n",
    "                # Existing greedy code\n",
    "                hidden = (torch.zeros(self.decoder.num_layers, 1, self.decoder.hidden_dim, device=src.device),\n",
    "                          torch.zeros(self.decoder.num_layers, 1, self.decoder.hidden_dim, device=src.device))\n",
    "                tgt_token = torch.tensor([[CHAR_MAP['<SOS>']]], device=src.device)\n",
    "                transcription = []\n",
    "                for i in range(max_length):\n",
    "                    logit, hidden = self.decoder.decode_step(tgt_token, memory_proj, enc_mask, hidden, i)\n",
    "                    pred_token = logit.argmax(-1).squeeze().item()\n",
    "                    if pred_token == CHAR_MAP['<EOS>']:\n",
    "                        break\n",
    "                    if pred_token in INV_CHAR_MAP:\n",
    "                        transcription.append(INV_CHAR_MAP[pred_token])\n",
    "                    tgt_token = torch.tensor([[pred_token]], device=src.device)\n",
    "                return ''.join(transcription)\n",
    "            else:\n",
    "                # Simple beam search implementation\n",
    "                beams = [{'seq': [CHAR_MAP['<SOS>']], 'score': 0.0, 'hidden': (torch.zeros(self.decoder.num_layers, 1, self.decoder.hidden_dim, device=src.device),\n",
    "                                                                             torch.zeros(self.decoder.num_layers, 1, self.decoder.hidden_dim, device=src.device))}]\n",
    "                for step in range(max_length):\n",
    "                    new_beams = []\n",
    "                    for beam in beams:\n",
    "                        tgt_token = torch.tensor([[beam['seq'][-1]]], device=src.device)\n",
    "                        logit, new_hidden = self.decoder.decode_step(tgt_token, memory_proj, enc_mask, beam['hidden'], step)\n",
    "                        probs = torch.log_softmax(logit.squeeze(0).squeeze(0), dim=-1)\n",
    "                        topk_probs, topk_tokens = probs.topk(beam_width)\n",
    "                        for p, t in zip(topk_probs, topk_tokens):\n",
    "                            new_seq = beam['seq'] + [t.item()]\n",
    "                            new_score = beam['score'] + p.item()\n",
    "                            new_beams.append({'seq': new_seq, 'score': new_score, 'hidden': new_hidden})\n",
    "                    beams = sorted(new_beams, key=lambda b: b['score'], reverse=True)[:beam_width]\n",
    "                    if beams[0]['seq'][-1] == CHAR_MAP['<EOS>']:\n",
    "                        break\n",
    "                best_seq = beams[0]['seq'][1:]  # Skip <SOS>\n",
    "                transcription = [INV_CHAR_MAP[t] for t in best_seq if t in INV_CHAR_MAP and t != CHAR_MAP['<EOS>']]\n",
    "                return ''.join(transcription)\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()  \n",
    "    total_loss = 0\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for mels, targets, mel_lens, target_lens in dataloader:\n",
    "            mels = mels.to(device)\n",
    "            targets = targets.to(device)\n",
    "            mel_lens = mel_lens.to(device)\n",
    "            target_lens = target_lens.to(device)\n",
    "\n",
    "            input_tgt = targets[:, :-1]\n",
    "            label = targets[:, 1:]\n",
    "            input_tgt_lens = target_lens - 1\n",
    "            \n",
    "            logits = model(mels, input_tgt, mel_lens, input_tgt_lens)\n",
    "            loss = criterion(logits.reshape(-1, VOCAB_SIZE), label.reshape(-1))\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03350463-a62c-4960-ba67-d49f630719a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AudioDataset(CSV_PATH)\n",
    "val_dataset = AudioDataset(VAL_CSV_PATH)  \n",
    "\n",
    "BATCH_SIZE = 64\n",
    "dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn) \n",
    "\n",
    "model = ASRModel()\n",
    "model = model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05,momentum=0.8)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=CHAR_MAP['<PAD>'])\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6)\n",
    "early_stopping_patience = 7\n",
    "patience_counter = 3\n",
    "best_val_loss = math.inf\n",
    "best_model_path = 'asr_best_model.pth'\n",
    "\n",
    "num_epochs = 70\n",
    "CLIP_VALUE = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdca84ad-90e7-4545-85b9-1aedbe468cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 (Train): 100%|█████████████████| 94/94 [00:43<00:00,  2.15it/s, batch_loss=2.9288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed, Train Loss: 2.9573, Val Loss: 2.9212, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 (Train): 100%|█████████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=2.8124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed, Train Loss: 2.8571, Val Loss: 2.8184, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 (Train): 100%|█████████████████| 94/94 [00:42<00:00,  2.19it/s, batch_loss=2.6259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed, Train Loss: 2.7165, Val Loss: 2.6490, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 (Train): 100%|█████████████████| 94/94 [00:42<00:00,  2.20it/s, batch_loss=2.4410]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed, Train Loss: 2.5406, Val Loss: 2.4842, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 (Train): 100%|█████████████████| 94/94 [00:42<00:00,  2.20it/s, batch_loss=2.3704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed, Train Loss: 2.4117, Val Loss: 2.3991, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 (Train): 100%|█████████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=2.2747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 completed, Train Loss: 2.3386, Val Loss: 2.3390, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 (Train): 100%|█████████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=2.2230]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed, Train Loss: 2.2798, Val Loss: 2.2871, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 (Train): 100%|█████████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=2.1780]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 completed, Train Loss: 2.2319, Val Loss: 2.2455, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 (Train): 100%|█████████████████| 94/94 [00:42<00:00,  2.19it/s, batch_loss=2.1595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 completed, Train Loss: 2.1877, Val Loss: 2.2103, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 (Train): 100%|████████████████| 94/94 [00:43<00:00,  2.19it/s, batch_loss=2.1134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 completed, Train Loss: 2.1480, Val Loss: 2.1702, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 (Train): 100%|████████████████| 94/94 [00:43<00:00,  2.18it/s, batch_loss=2.0470]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 completed, Train Loss: 2.1118, Val Loss: 2.1311, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.19it/s, batch_loss=2.0395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 completed, Train Loss: 2.0806, Val Loss: 2.0969, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=2.0340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 completed, Train Loss: 2.0479, Val Loss: 2.0775, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.24it/s, batch_loss=2.0346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 completed, Train Loss: 2.0203, Val Loss: 2.0645, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=1.9875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 completed, Train Loss: 1.9980, Val Loss: 2.0401, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.20it/s, batch_loss=1.8912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 completed, Train Loss: 1.9690, Val Loss: 2.0092, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 (Train): 100%|████████████████| 94/94 [00:43<00:00,  2.15it/s, batch_loss=1.9159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 completed, Train Loss: 1.9453, Val Loss: 1.9838, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.20it/s, batch_loss=1.9084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 completed, Train Loss: 1.9240, Val Loss: 1.9815, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 (Train): 100%|████████████████| 94/94 [00:43<00:00,  2.15it/s, batch_loss=1.8507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 completed, Train Loss: 1.9018, Val Loss: 1.9465, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=1.9019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 completed, Train Loss: 1.8821, Val Loss: 1.9335, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.22it/s, batch_loss=1.8213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 completed, Train Loss: 1.8606, Val Loss: 1.9250, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.22it/s, batch_loss=1.8256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 completed, Train Loss: 1.8402, Val Loss: 1.9273, LR: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.23it/s, batch_loss=1.7919]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 completed, Train Loss: 1.8187, Val Loss: 1.8752, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=1.8003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 completed, Train Loss: 1.8023, Val Loss: 1.8697, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.20it/s, batch_loss=1.7600]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 completed, Train Loss: 1.7836, Val Loss: 1.8799, LR: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.24it/s, batch_loss=1.7236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 completed, Train Loss: 1.7637, Val Loss: 1.8420, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.23it/s, batch_loss=1.7028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 completed, Train Loss: 1.7465, Val Loss: 1.8248, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 (Train): 100%|████████████████| 94/94 [00:41<00:00,  2.25it/s, batch_loss=1.7130]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 completed, Train Loss: 1.7263, Val Loss: 1.8271, LR: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.20it/s, batch_loss=1.7201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 completed, Train Loss: 1.7111, Val Loss: 1.8287, LR: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=1.6770]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 completed, Train Loss: 1.6957, Val Loss: 1.8171, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.22it/s, batch_loss=1.6812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 completed, Train Loss: 1.6809, Val Loss: 1.8255, LR: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.23it/s, batch_loss=1.7477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 completed, Train Loss: 1.6678, Val Loss: 1.7707, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 (Train): 100%|████████████████| 94/94 [00:43<00:00,  2.15it/s, batch_loss=1.5990]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 completed, Train Loss: 1.6487, Val Loss: 1.7811, LR: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.19it/s, batch_loss=1.6452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 completed, Train Loss: 1.6281, Val Loss: 1.7456, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.23it/s, batch_loss=1.5539]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 completed, Train Loss: 1.6154, Val Loss: 1.7573, LR: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 (Train): 100%|████████████████| 94/94 [00:41<00:00,  2.24it/s, batch_loss=1.6469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 completed, Train Loss: 1.6031, Val Loss: 1.7295, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.23it/s, batch_loss=1.5994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 completed, Train Loss: 1.5850, Val Loss: 1.7430, LR: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.22it/s, batch_loss=1.6169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 completed, Train Loss: 1.5692, Val Loss: 1.7249, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 (Train): 100%|████████████████| 94/94 [00:43<00:00,  2.18it/s, batch_loss=1.5662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 completed, Train Loss: 1.5591, Val Loss: 1.7236, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=1.5419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 completed, Train Loss: 1.5419, Val Loss: 1.7088, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.19it/s, batch_loss=1.5100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 completed, Train Loss: 1.5280, Val Loss: 1.7368, LR: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.20it/s, batch_loss=1.5429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 completed, Train Loss: 1.5157, Val Loss: 1.6834, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.23it/s, batch_loss=1.5096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 completed, Train Loss: 1.5006, Val Loss: 1.6844, LR: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.20it/s, batch_loss=1.4315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 completed, Train Loss: 1.4880, Val Loss: 1.6631, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=1.5272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 completed, Train Loss: 1.4741, Val Loss: 1.7190, LR: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 (Train): 100%|████████████████| 94/94 [00:41<00:00,  2.26it/s, batch_loss=1.4638]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 completed, Train Loss: 1.4626, Val Loss: 1.6932, LR: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.23it/s, batch_loss=1.4318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 completed, Train Loss: 1.4488, Val Loss: 1.6580, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.23it/s, batch_loss=1.4290]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 completed, Train Loss: 1.4392, Val Loss: 1.6520, LR: 0.050000 (Saving Best Model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.20it/s, batch_loss=1.3999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 completed, Train Loss: 1.4204, Val Loss: 1.6603, LR: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 (Train): 100%|████████████████| 94/94 [00:42<00:00,  2.21it/s, batch_loss=1.3810]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 completed, Train Loss: 1.4101, Val Loss: 1.6575, LR: 0.050000\n",
      "\n",
      "Loading best model weights from asr_best_model.pth (Val Loss: 1.6520).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch+1}/{num_epochs} (Train)\")\n",
    "    \n",
    "    for batch_idx, (mels, targets, mel_lens, target_lens) in progress_bar:\n",
    "        if total_train_loss != total_train_loss and batch_idx > 0:\n",
    "            print(\"\\nGradient Explosion detected mid-epoch. Breaking...\")\n",
    "            break\n",
    "        mels = mels.to(device)\n",
    "        targets = targets.to(device)\n",
    "        mel_lens = mel_lens.to(device)\n",
    "        target_lens = target_lens.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_tgt = targets[:, :-1]\n",
    "        label = targets[:, 1:]\n",
    "        input_tgt_lens = target_lens - 1\n",
    "\n",
    "        logits = model(mels, input_tgt, mel_lens, input_tgt_lens)\n",
    "        loss = criterion(logits.reshape(-1, VOCAB_SIZE), label.reshape(-1))\n",
    "\n",
    "        if loss.isnan():\n",
    "            print(f\"\\nWarning: NaN loss detected in batch {batch_idx+1}. Skipping batch.\")\n",
    "            continue\n",
    "        if loss.isinf():\n",
    "            print(f\"\\nWarning: Inf loss detected in batch {batch_idx+1}. Skipping batch.\")\n",
    "            continue\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_VALUE)\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        progress_bar.set_postfix(batch_loss=f\"{loss.item():.4f}\")  \n",
    "\n",
    "    if total_train_loss == total_train_loss: \n",
    "        avg_train_loss = total_train_loss / len(dataloader)\n",
    "    else:\n",
    "        avg_train_loss = float('nan')\n",
    "\n",
    "    avg_val_loss = evaluate(model, val_dataloader, criterion, device)\n",
    "    \n",
    "    # Step the Learning Rate Scheduler\n",
    "    if avg_val_loss == avg_val_loss:\n",
    "        scheduler.step(avg_val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    # Early Stopping Check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path) \n",
    "        status = \" (Saving Best Model)\"\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        status = \"\"\n",
    "        \n",
    "    print(f'Epoch {epoch+1} completed, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, LR: {current_lr:.6f}{status}')\n",
    "    \n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(f\"\\nEarly stopping triggered after {patience_counter} epochs without improvement on Val Loss.\")\n",
    "        break\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    print(f\"\\nLoading best model weights from {best_model_path} (Val Loss: {best_val_loss:.4f}).\")\n",
    "    model.load_state_dict(torch.load(best_model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "789c2454-dd90-42c5-9947-4ae9cfa22f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting transcripts: 100%|████████████████████████████| 1000/1000 [01:10<00:00, 14.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of predicted_df:\n",
      "                  file                                         transcript\n",
      "0  geo/clips/dev_0.wav  teo eztaz tri la tinpo de la tinpo de la gunom...\n",
      "1  geo/clips/dev_1.wav  pozti la blej gunomonu eztaz gunzederataj de l...\n",
      "2  geo/clips/dev_2.wav                                  ĝi eztaz zenilita\n",
      "3  geo/clips/dev_3.wav                     ĝi eztaz zenjuru de la zceemco\n",
      "4  geo/clips/dev_4.wav  ĝi eztaz ĉive ĉive gaj la ĉiverzamtojm ĉive ĉi...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "MODEL_PATH = 'asr_best_model.pth'\n",
    "TEST_CSV_PATH = \"geo/dev.csv\"\n",
    "model = ASRModel().to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "# Load test CSV\n",
    "test_df = pd.read_csv(TEST_CSV_PATH)\n",
    "predicted_df = test_df.copy()\n",
    "predicted_df['transcript'] = predicted_df['transcript'].astype('object') # Fix dtype upfront\n",
    "# Predict for each row with progress and error handling\n",
    "for idx, row in tqdm(predicted_df.iterrows(), total=len(predicted_df), desc=\"Predicting transcripts\"):\n",
    "    try:\n",
    "        audio_path = row['file']\n",
    "        waveform, sr = torchaudio.load(audio_path)\n",
    "        if sr != SAMPLE_RATE:\n",
    "            waveform = torchaudio.transforms.Resample(sr, SAMPLE_RATE)(waveform)\n",
    "        mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=SAMPLE_RATE, n_mels=N_MELS, hop_length=HOP_LENGTH, win_length=WIN_LENGTH, n_fft=WIN_LENGTH\n",
    "        )\n",
    "        mel_spec = torch.log(mel_transform(waveform) + 1e-9).squeeze(0).transpose(0, 1)\n",
    "        src_length = torch.tensor([mel_spec.size(0)])\n",
    "        prediction = model.predict(mel_spec.to(device), src_length.to(device), beam_width=3)\n",
    "        predicted_df.at[idx, 'transcript'] = prediction\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing index {idx} (file: {audio_path}): {e}\")\n",
    "        predicted_df.at[idx, 'transcript'] = '' # Set empty on error\n",
    "# Verify DataFrame before saving\n",
    "print(\"\\nSample of predicted_df:\")\n",
    "print(predicted_df.head())\n",
    "# Ensure transcript column contains only strings\n",
    "predicted_df['transcript'] = predicted_df['transcript'].fillna('').astype(str)\n",
    "# Save updated CSV\n",
    "output_csv = 'predicted_dev.csv'\n",
    "predicted_df.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2c91508-2bab-430f-a36c-b60e4aa03e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 1.104522745201157\n",
      "CER: 0.7869850937650265\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from jiwer import wer, cer\n",
    "\n",
    "df_gt = pd.read_csv(\"geo/dev.csv\")               # ground truth\n",
    "df_pred = pd.read_csv(\"predicted_dev.csv\")   # predictions\n",
    "\n",
    "# Ensure both are sorted the same way (optional but recommended)\n",
    "df_gt = df_gt.sort_values(\"file\").reset_index(drop=True)\n",
    "df_pred = df_pred.sort_values(\"file\").reset_index(drop=True)\n",
    "\n",
    "df_gt['transcript'] = df_gt['transcript'].fillna('').astype(str)\n",
    "df_pred['transcript'] = df_pred['transcript'].fillna('').astype(str)\n",
    "\n",
    "gt_texts = df_gt[\"transcript\"].tolist()\n",
    "pred_texts = df_pred[\"transcript\"].tolist()\n",
    "\n",
    "\n",
    "overall_wer = wer(gt_texts, pred_texts)\n",
    "overall_cer = cer(gt_texts, pred_texts)\n",
    "\n",
    "print(\"WER:\", overall_wer)\n",
    "print(\"CER:\", overall_cer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796f4c3c-e464-4c5e-8272-c7c4b76b7c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
