{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e794d9-8cf7-4653-a16f-bb0fc4868e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2FeatureExtractor\n",
    "from peft import PeftModel\n",
    "\n",
    "# --- Configuration ---\n",
    "CONFIG = {\n",
    "    \"base_model\": \"facebook/wav2vec2-large-xlsr-53\",\n",
    "    \"checkpoint_path\": \"xlsr_lora_gibberish_best\", # Your saved LoRA folder\n",
    "    \"vocab_path\": \"vocab.json\",                    # Your saved Vocab file\n",
    "    \"input_csv\": \"geo/test.csv\",                   # Input file\n",
    "    \"output_csv\": \"geo/test_predictions.csv\",      # Output file\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "def load_resources():\n",
    "    print(f\"Using device: {CONFIG['device']}\")\n",
    "    \n",
    "    # 1. Load Vocabulary\n",
    "    if not os.path.exists(CONFIG[\"vocab_path\"]):\n",
    "        raise FileNotFoundError(f\"Vocab file not found at {CONFIG['vocab_path']}. Did you save it during training?\")\n",
    "        \n",
    "    print(\"Loading vocabulary...\")\n",
    "    with open(CONFIG[\"vocab_path\"], \"r\") as f:\n",
    "        vocab_dict = json.load(f)\n",
    "    # Create inverse vocab (ID -> Char) for decoding\n",
    "    inv_vocab = {v: k for k, v in vocab_dict.items()}\n",
    "    \n",
    "    # 2. Load Base Model\n",
    "    print(\"Loading Base Model...\")\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(\n",
    "        CONFIG[\"base_model\"], \n",
    "        vocab_size=len(vocab_dict),\n",
    "        pad_token_id=vocab_dict.get(\"<pad>\", 0),\n",
    "        ignore_mismatched_sizes=True,\n",
    "        token=False # Force anonymous to avoid 401 errors\n",
    "    )\n",
    "    \n",
    "    # 3. Load LoRA Adapters\n",
    "    print(f\"Loading LoRA Adapters from {CONFIG['checkpoint_path']}...\")\n",
    "    if not os.path.exists(CONFIG[\"checkpoint_path\"]):\n",
    "        raise FileNotFoundError(f\"Checkpoint folder not found at {CONFIG['checkpoint_path']}\")\n",
    "        \n",
    "    model = PeftModel.from_pretrained(model, CONFIG[\"checkpoint_path\"])\n",
    "    model.to(CONFIG[\"device\"])\n",
    "    model.eval()\n",
    "    \n",
    "    # 4. Load Processor\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(CONFIG[\"base_model\"], token=False)\n",
    "    \n",
    "    return model, processor, inv_vocab\n",
    "\n",
    "def transcribe_single_audio(audio_path, model, processor, inv_vocab):\n",
    "    \"\"\"\n",
    "    Reads audio, resamples, and returns string transcription.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(audio_path):\n",
    "        return \"[ERROR: FILE NOT FOUND]\"\n",
    "\n",
    "    try:\n",
    "        # Load Audio\n",
    "        waveform, sr = torchaudio.load(audio_path)\n",
    "        \n",
    "        # Resample to 16k if needed\n",
    "        if sr != 16000:\n",
    "            waveform = torchaudio.transforms.Resample(sr, 16000)(waveform)\n",
    "        \n",
    "        # Convert Stereo to Mono\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        \n",
    "        # Preprocess\n",
    "        input_values = processor(\n",
    "            waveform.squeeze().numpy(), \n",
    "            sampling_rate=16000, \n",
    "            return_tensors=\"pt\"\n",
    "        ).input_values\n",
    "        \n",
    "        input_values = input_values.to(CONFIG[\"device\"])\n",
    "\n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_values).logits\n",
    "        \n",
    "        # Greedy Decode (Argmax)\n",
    "        pred_ids = torch.argmax(logits, dim=-1)\n",
    "        pred_ids = pred_ids[0].cpu().tolist()\n",
    "        \n",
    "        # Decode to String (CTC Logic)\n",
    "        pred_str = []\n",
    "        prev_token = -1\n",
    "        for token in pred_ids:\n",
    "            if token != prev_token and token != 0: # 0 is <pad>\n",
    "                char = inv_vocab.get(token, \"\")\n",
    "                # Filter out special tokens just in case\n",
    "                if char not in [\"<s>\", \"</s>\", \"<unk>\", \"<pad>\"]:\n",
    "                    pred_str.append(char)\n",
    "            prev_token = token\n",
    "            \n",
    "        # Join characters and replace pipe with space\n",
    "        final_text = \"\".join(pred_str).replace(\"|\", \" \")\n",
    "        return final_text\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"[ERROR: {str(e)}]\"\n",
    "\n",
    "def main():\n",
    "    # 1. Setup Resources\n",
    "    model, processor, inv_vocab = load_resources()\n",
    "    \n",
    "    # 2. Load CSV\n",
    "    print(f\"Reading input CSV: {CONFIG['input_csv']}\")\n",
    "    df = pd.read_csv(CONFIG[\"input_csv\"], delimiter=\",\")\n",
    "    \n",
    "    # Ensure 'transcript' column exists\n",
    "    if 'transcript' not in df.columns:\n",
    "        df['transcript'] = \"\"\n",
    "    \n",
    "    # 3. Iterate and Predict\n",
    "    print(f\"Starting inference on {len(df)} files...\")\n",
    "    \n",
    "    # We iterate through the DataFrame using tqdm for a progress bar\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), unit=\"file\"):\n",
    "        file_path = row['file']\n",
    "        \n",
    "        # Generate transcription\n",
    "        transcription = transcribe_single_audio(file_path, model, processor, inv_vocab)\n",
    "        \n",
    "        # Save to DataFrame in memory\n",
    "        df.at[index, 'transcript'] = transcription\n",
    "\n",
    "    # 4. Save Results\n",
    "    print(f\"Saving results to {CONFIG['output_csv']}...\")\n",
    "    df.to_csv(CONFIG['output_csv'], index=False)\n",
    "    print(\"Done!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
